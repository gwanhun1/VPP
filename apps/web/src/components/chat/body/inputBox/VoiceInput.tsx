import { useState, useCallback, useEffect } from 'react';

declare global {
  type Window = {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  };
}

type SpeechRecognitionEvent = {
  results: {
    [key: number]: {
      [key: number]: {
        transcript: string;
        confidence: number;
      };
    };
  };
  error?: string;
};

type SpeechRecognition = {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start(): void;
  stop(): void;
  onstart: () => void;
  onend: () => void;
  onerror: (event: { error: string }) => void;
  onresult: (event: SpeechRecognitionEvent) => void;
};

const getSpeechRecognition = (): (new () => SpeechRecognition) | null => {
  if (typeof window !== 'undefined') {
    return window.SpeechRecognition || window.webkitSpeechRecognition || null;
  }
  return null;
};

export const useSpeechToText = (onTextReceived?: (text: string) => void) => {
  const [text, setText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isSupported, setIsSupported] = useState(true);
  const [permissionStatus, setPermissionStatus] = useState<
    'granted' | 'denied' | 'prompt'
  >('prompt');

  // ë§ˆì´í¬ ê¶Œí•œ í™•ì¸
  useEffect(() => {
    if (navigator.permissions && navigator.permissions.query) {
      navigator.permissions
        .query({ name: 'microphone' as PermissionName })
        .then((result) => {
          setPermissionStatus(result.state as 'granted' | 'denied' | 'prompt');

          result.onchange = () => {
            setPermissionStatus(
              result.state as 'granted' | 'denied' | 'prompt'
            );
          };
        });
    }
  }, []);

  const startListening = useCallback(() => {
    const SpeechRecognition = getSpeechRecognition();
    if (!SpeechRecognition) {
      setIsSupported(false);
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•Šì•„ìš”.');
      return;
    }

    // ì´ë¯¸ ë“£ê³  ìˆë‹¤ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
    if (isListening) return;

    const recognition = new SpeechRecognition();
    recognition.lang = 'ko-KR'; // í•œêµ­ì–´ ì¸ì‹
    recognition.continuous = false; // í•œ ë¬¸ì¥ë§Œ ì¸ì‹
    recognition.interimResults = false; // ì¤‘ê°„ ê²°ê³¼ ì œì™¸

    recognition.onstart = () => {
      setIsListening(true);
      console.log('ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘');
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const transcript = event.results[0][0].transcript;
      console.log('ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:', transcript);
      setText(transcript);

      // ì½œë°± í•¨ìˆ˜ê°€ ì œê³µë˜ì—ˆë‹¤ë©´ í˜¸ì¶œ
      if (onTextReceived) {
        onTextReceived(transcript);
      }
    };

    recognition.onerror = (event: { error: string }) => {
      console.error('âŒ ì¸ì‹ ì˜¤ë¥˜:', event.error);
      setIsListening(false);

      if (event.error === 'not-allowed') {
        setPermissionStatus('denied');
        alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      }
    };

    recognition.onend = () => {
      console.log('ğŸ›‘ ìŒì„± ì¸ì‹ ì¢…ë£Œ');
      setIsListening(false);
    };

    try {
      recognition.start(); // ì¸ì‹ ì‹œì‘
    } catch (error) {
      console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:', error);
      setIsListening(false);
    }
  }, [isListening, onTextReceived]);

  const stopListening = useCallback(() => {
    setIsListening(false);
    // isListening ìƒíƒœë¥¼ ë³€ê²½í•˜ê³  ì¸ì‹ì€ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œ
  }, []);

  return {
    text,
    isListening,
    isSupported,
    permissionStatus,
    startListening,
    stopListening,
  };
};
